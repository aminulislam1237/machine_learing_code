{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8590845,"sourceType":"datasetVersion","datasetId":5138606}],"dockerImageVersionId":31040,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import necessary libraries\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms, datasets\nfrom timm import create_model\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom tqdm import tqdm\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\nfrom sklearn.preprocessing import label_binarize\nimport os\nimport shutil\nimport random\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport numpy as np\nfrom PIL import Image\nimport math\nfrom math import floor\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.metrics import roc_auc_score\nimport tensorflow as tf\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.layers import Flatten, Dense, Dropout\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Path to the dataset directory\ndataset_dir = '/kaggle/input/sugarcane-leaf-disease-dataset/Sugarcane Leaf Disease Dataset'\n\n# Categories\ncategories = ['Healthy', 'Mosaic', 'Rust', 'RedRot', 'Yellow']\n\n# Number of images to display per category\nnum_images_per_category = 5\n\n# Create a figure with subplots (rows = categories, cols = num_images_per_category)\nfig, axes = plt.subplots(len(categories), num_images_per_category, figsize=(15, 10))\n\nfor i, category in enumerate(categories):\n    # Path to the category directory\n    category_dir = os.path.join(dataset_dir, category)\n    \n    # Get a list of images in the category\n    images = os.listdir(category_dir)\n    \n    # Randomly select 5 images\n    selected_images = random.sample(images, num_images_per_category)\n    \n    for j, image_name in enumerate(selected_images):\n        # Load the image\n        img_path = os.path.join(category_dir, image_name)\n        img = mpimg.imread(img_path)\n        \n        # Display the image\n        axes[i, j].imshow(img)\n        axes[i, j].axis('off')  # Hide the axes\n        if j == 0:\n            axes[i, j].set_title(category, fontsize=12)\n\n# Adjust the spacing between subplots\nplt.subplots_adjust(wspace=0.1, hspace=0.3)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def split_dataset(dataset_dir, output_dir, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1):\n    # Create output directories for train, val, test sets\n    train_dir = os.path.join(output_dir, 'Train')\n    val_dir = os.path.join(output_dir, 'Validation')\n    test_dir = os.path.join(output_dir, 'Test')\n\n    os.makedirs(train_dir, exist_ok=True)\n    os.makedirs(val_dir, exist_ok=True)\n    os.makedirs(test_dir, exist_ok=True)\n\n    # Loop through each class (directory) in the dataset\n    for class_name in os.listdir(dataset_dir):\n        class_dir = os.path.join(dataset_dir, class_name)\n        if not os.path.isdir(class_dir):\n            continue\n        \n        # List all image files in the class directory\n        image_files = os.listdir(class_dir)\n        \n        # Shuffle the images randomly\n        random.shuffle(image_files)\n        \n        # Calculate the split indices\n        total_images = len(image_files)\n        train_count = floor(total_images * train_ratio)\n        val_count = floor(total_images * val_ratio)\n        test_count = total_images - train_count - val_count  # The rest goes to test\n\n        # Split the images\n        train_files = image_files[:train_count]\n        val_files = image_files[train_count:train_count + val_count]\n        test_files = image_files[train_count + val_count:]\n\n        # Copy files to the appropriate directories\n        for file in train_files:\n            src = os.path.join(class_dir, file)\n            dest = os.path.join(train_dir, class_name)\n            os.makedirs(dest, exist_ok=True)\n            shutil.copy(src, dest)\n\n        for file in val_files:\n            src = os.path.join(class_dir, file)\n            dest = os.path.join(val_dir, class_name)\n            os.makedirs(dest, exist_ok=True)\n            shutil.copy(src, dest)\n\n        for file in test_files:\n            src = os.path.join(class_dir, file)\n            dest = os.path.join(test_dir, class_name)\n            os.makedirs(dest, exist_ok=True)\n            shutil.copy(src, dest)\n\n    print(\"Dataset successfully split into train, validation, and test sets.\")\n\n#  Usage\ndataset_dir = '/kaggle/input/sugarcane-leaf-disease-dataset/Sugarcane Leaf Disease Dataset' \noutput_dir = '/kaggle/working/'\n\nsplit_dataset(dataset_dir, output_dir)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set device (GPU if available, else CPU)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define hyperparameters\nbatch_size = 32\nlearning_rate = 1e-5\nnum_epochs = 25\nnum_classes = 5  # Update based on your dataset","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Data transformations\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data = datasets.ImageFolder(root='/kaggle/working/Train', transform=transform)\nval_data = datasets.ImageFolder(root='/kaggle/working/Test', transform=transform)\n\ntrain_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Class names\nclass_names = train_data.classes  # Extracts class labels from dataset\n\n# Load pre-trained Vision Transformer (ViT)\nmodel = create_model('vit_base_patch16_224', pretrained=True)\nmodel.head = nn.Linear(model.head.in_features, num_classes)  # Adjust output layer for classification\nmodel = model.to(device)\n\n# Loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Lists to store training and validation metrics\ntrain_losses = []\ntrain_accuracies = []\nval_losses = []\nval_accuracies = []","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Training and validation loop\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    correct_preds = 0\n    total_preds = 0\n\n    for inputs, labels in tqdm(train_loader):\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        _, preds = torch.max(outputs, 1)\n        correct_preds += torch.sum(preds == labels).item()\n        total_preds += labels.size(0)\n\n    epoch_loss = running_loss / len(train_loader)\n    epoch_accuracy = correct_preds / total_preds\n    train_losses.append(epoch_loss)\n    train_accuracies.append(epoch_accuracy)\n\n    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}\")\n\n    # Validation loop\n    model.eval()\n    val_loss = 0.0\n    correct_preds = 0\n    total_preds = 0\n\n    with torch.no_grad():\n        for inputs, labels in val_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n\n            _, preds = torch.max(outputs, 1)\n            correct_preds += torch.sum(preds == labels).item()\n            total_preds += labels.size(0)\n\n    val_epoch_loss = val_loss / len(val_loader)\n    val_epoch_accuracy = correct_preds / total_preds\n    val_losses.append(val_epoch_loss)\n    val_accuracies.append(val_epoch_accuracy)\n\n    print(f\"Validation Accuracy: {val_epoch_accuracy:.4f}, Validation Loss: {val_epoch_loss:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot training and validation loss curves\nplt.figure(figsize=(10, 5))\nplt.plot(range(1, num_epochs + 1), train_losses, label=\"Training Loss\", color=\"blue\")\nplt.plot(range(1, num_epochs + 1), val_losses, label=\"Validation Loss\", color=\"red\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.title(\"Training and Validation Loss Curve\")\nplt.legend()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot training and validation accuracy curves\nplt.figure(figsize=(10, 5))\nplt.plot(range(1, num_epochs + 1), train_accuracies, label=\"Training Accuracy\", color=\"green\")\nplt.plot(range(1, num_epochs + 1), val_accuracies, label=\"Validation Accuracy\", color=\"orange\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"Training and Validation Accuracy Curve\")\nplt.legend()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Collect predictions and true labels\nall_preds = []\nall_labels = []\n\nmodel.eval()\nwith torch.no_grad():\n    for inputs, labels in val_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        outputs = model(inputs)\n        _, preds = torch.max(outputs, 1)\n\n        all_preds.extend(preds.cpu().numpy())\n        all_labels.extend(labels.cpu().numpy())\n\n# Classification report\nprint(\"\\nClassification Report:\")\nprint(classification_report(all_labels, all_preds, target_names=class_names))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Confusion matrix\ncm = confusion_matrix(all_labels, all_preds)\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"coolwarm\", xticklabels=class_names, yticklabels=class_names)\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}