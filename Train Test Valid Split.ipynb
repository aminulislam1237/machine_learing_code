{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 169681,
     "status": "ok",
     "timestamp": 1747207328727,
     "user": {
      "displayName": "S. M. Shaqib",
      "userId": "04470945011620510879"
     },
     "user_tz": -360
    },
    "id": "I60QC6BIpeb_",
    "outputId": "d736dc44-0652-4232-dc13-a766773df062"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class counts: {'[Malignant] Pro-B': 979, 'Benign': 979, '[Malignant] Pre-B': 979, '[Malignant] early Pre-B': 979}\n",
      "Class: [Malignant] Pro-B\n",
      "  Train: 685 images\n",
      "  Validation: 147 images\n",
      "  Test: 147 images\n",
      "Class: Benign\n",
      "  Train: 685 images\n",
      "  Validation: 147 images\n",
      "  Test: 147 images\n",
      "Class: [Malignant] Pre-B\n",
      "  Train: 685 images\n",
      "  Validation: 147 images\n",
      "  Test: 147 images\n",
      "Class: [Malignant] early Pre-B\n",
      "  Train: 685 images\n",
      "  Validation: 147 images\n",
      "  Test: 147 images\n",
      "\n",
      "Train class counts: {'[Malignant] Pro-B': 685, 'Benign': 685, '[Malignant] Pre-B': 685, '[Malignant] early Pre-B': 685}\n",
      "\n",
      "Val class counts: {'[Malignant] Pro-B': 147, 'Benign': 147, '[Malignant] Pre-B': 147, '[Malignant] early Pre-B': 147}\n",
      "\n",
      "Test class counts: {'[Malignant] Pro-B': 147, 'Benign': 147, '[Malignant] Pre-B': 147, '[Malignant] early Pre-B': 147}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def create_split_dirs(output_base_path, split_names=['train', 'val', 'test']):\n",
    "    \"\"\"Create directories for train, validation, and test splits.\"\"\"\n",
    "    for split in split_names:\n",
    "        split_path = os.path.join(output_base_path, split)\n",
    "        if not os.path.exists(split_path):\n",
    "            os.makedirs(split_path)\n",
    "\n",
    "def split_dataset(dataset_path, output_base_path, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15, random_seed=42):\n",
    "    \"\"\"\n",
    "    Split dataset into train, validation, and test sets while preserving class distribution.\n",
    "\n",
    "    Args:\n",
    "        dataset_path (str): Path to the original dataset directory\n",
    "        output_base_path (str): Path to save the split datasets\n",
    "        train_ratio (float): Proportion of data for training (default: 0.7)\n",
    "        val_ratio (float): Proportion of data for validation (default: 0.15)\n",
    "        test_ratio (float): Proportion of data for testing (default: 0.15)\n",
    "        random_seed (int): Seed for reproducibility\n",
    "    \"\"\"\n",
    "    # Validate ratios\n",
    "    if abs(train_ratio + val_ratio + test_ratio - 1.0) > 0.001:\n",
    "        raise ValueError(\"Train, validation, and test ratios must sum to 1.0\")\n",
    "\n",
    "    # Set random seed for reproducibility\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "    # Create train, val, test directories\n",
    "    create_split_dirs(output_base_path)\n",
    "\n",
    "    # Process each class\n",
    "    for class_name in os.listdir(dataset_path):\n",
    "        class_path = os.path.join(dataset_path, class_name)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "\n",
    "        # Get list of images in the class\n",
    "        images = [f for f in os.listdir(class_path) if os.path.isfile(os.path.join(class_path, f))]\n",
    "        if not images:\n",
    "            print(f\"Warning: No images found in {class_name}\")\n",
    "            continue\n",
    "\n",
    "        # Shuffle images\n",
    "        random.shuffle(images)\n",
    "\n",
    "        # Split images into train, val, test\n",
    "        train_images, temp_images = train_test_split(images, train_size=train_ratio, random_state=random_seed)\n",
    "        val_size = val_ratio / (val_ratio + test_ratio)  # Proportion of remaining data for validation\n",
    "        val_images, test_images = train_test_split(temp_images, train_size=val_size, random_state=random_seed)\n",
    "\n",
    "        # Create class directories in train, val, test\n",
    "        for split_name in ['train', 'val', 'test']:\n",
    "            split_class_path = os.path.join(output_base_path, split_name, class_name)\n",
    "            if not os.path.exists(split_class_path):\n",
    "                os.makedirs(split_class_path)\n",
    "\n",
    "        # Copy images to respective directories\n",
    "        for img in train_images:\n",
    "            shutil.copy(os.path.join(class_path, img), os.path.join(output_base_path, 'train', class_name, img))\n",
    "        for img in val_images:\n",
    "            shutil.copy(os.path.join(class_path, img), os.path.join(output_base_path, 'val', class_name, img))\n",
    "        for img in test_images:\n",
    "            shutil.copy(os.path.join(class_path, img), os.path.join(output_base_path, 'test', class_name, img))\n",
    "\n",
    "        # Print split counts for verification\n",
    "        print(f\"Class: {class_name}\")\n",
    "        print(f\"  Train: {len(train_images)} images\")\n",
    "        print(f\"  Validation: {len(val_images)} images\")\n",
    "        print(f\"  Test: {len(test_images)} images\")\n",
    "\n",
    "def get_class_counts(dataset_path):\n",
    "    \"\"\"Count images per class in the dataset.\"\"\"\n",
    "    class_counts = {}\n",
    "    for class_name in os.listdir(dataset_path):\n",
    "        class_path = os.path.join(dataset_path, class_name)\n",
    "        if os.path.isdir(class_path):\n",
    "            class_counts[class_name] = len([f for f in os.listdir(class_path) if os.path.isfile(os.path.join(class_path, f))])\n",
    "    return class_counts\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Your dataset paths (modify as needed)\n",
    "    input_dataset_path = \"C:/Users/Rasel/Downloads/Compressed/archive_2\"\n",
    "    output_split_path = \"C:/Users/Rasel/Desktop/output dataset\"\n",
    "\n",
    "    # Print original class counts\n",
    "    print(\"Original class counts:\", get_class_counts(input_dataset_path))\n",
    "\n",
    "    # Split the dataset\n",
    "    split_dataset(input_dataset_path, output_split_path, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15)\n",
    "\n",
    "    # Verify split counts\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        split_path = os.path.join(output_split_path, split)\n",
    "        print(f\"\\n{split.capitalize()} class counts:\", get_class_counts(split_path))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMpNJ4x9IrM87ORQaYfGZ15",
   "mount_file_id": "12Cj7JaMb_xyvZnUB-scXxJW_DUaO4UTs",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
